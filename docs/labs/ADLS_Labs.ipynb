{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"mm5523@ic.ac.uk\"\n",
        "!git config --global user.name \"mau-mar\""
      ],
      "metadata": {
        "id": "syYnlmxe8URa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/machop"
      ],
      "metadata": {
        "id": "JicqeIDmqx8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 -R \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/machop\""
      ],
      "metadata": {
        "id": "BPwi2z5SxMZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "-EsF4SHMkfPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./ch train jsc-tiny jsc --max-epochs 10 --batch-size 256 # BASELINE jsc-tiny"
      ],
      "metadata": {
        "id": "D3VDuY-4HO6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tiny_lab1_experiments/learning_rate_experiments/software/tensorboard/lightning_logs\n"
      ],
      "metadata": {
        "id": "IBM8kvXC7PB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try model 10x larger than toy network\n",
        "\n",
        "!./ch train jsc-less-tiny jsc --max-epochs 10 --batch-size 256"
      ],
      "metadata": {
        "id": "5O_zLgO0yN_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tinyX10/software/tensorboard/lightning_logs\n"
      ],
      "metadata": {
        "id": "Jq3a8ev2W-eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "# Lab 2"
      ],
      "metadata": {
        "id": "qsofhHJYH8CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pprint import pprint as pp\n",
        "\n",
        "from chop.dataset import MaseDataModule, get_dataset_info\n",
        "from chop.tools.logger import set_logging_verbosity\n",
        "\n",
        "from chop.passes.graph import (\n",
        "    save_node_meta_param_interface_pass,\n",
        "    report_node_meta_param_analysis_pass,\n",
        "    profile_statistics_analysis_pass,\n",
        "    add_common_metadata_analysis_pass,\n",
        "    init_metadata_analysis_pass,\n",
        "    add_software_metadata_analysis_pass,\n",
        ")\n",
        "from chop.tools.get_input import InputGenerator\n",
        "from chop.tools.checkpoint_load import load_model\n",
        "from chop.ir import MaseGraph\n",
        "\n",
        "from chop.models import get_model_info, get_model\n",
        "\n",
        "set_logging_verbosity(\"info\")"
      ],
      "metadata": {
        "id": "2oiUYFL3IgGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Up the Dataset\n",
        "batch_size = 8\n",
        "model_name = \"jsc-tiny\"\n",
        "dataset_name = \"jsc\"\n",
        "\n",
        "\n",
        "data_module = MaseDataModule(\n",
        "    name=dataset_name,\n",
        "    batch_size=batch_size,\n",
        "    model_name=model_name,\n",
        "    num_workers=0,\n",
        ")\n",
        "data_module.prepare_data()\n",
        "data_module.setup()"
      ],
      "metadata": {
        "id": "dAJ0TERwIuOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Up the Model\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tiny_baseline/software/training_ckpts/best-jsc_tiny_ep10_bs256_baseline.ckpt\"\n",
        "model_info = get_model_info(model_name)\n",
        "model = get_model(\n",
        "    model_name,\n",
        "    task=\"cls\",\n",
        "    dataset_info=data_module.dataset_info,\n",
        "    pretrained=False)\n",
        "\n",
        "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
      ],
      "metadata": {
        "id": "8RHexZm-JDvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Dummy Data In\n",
        "\n",
        "# get the input generator\n",
        "input_generator = InputGenerator(\n",
        "    data_module=data_module,\n",
        "    model_info=model_info,\n",
        "    task=\"cls\",\n",
        "    which_dataloader=\"train\",\n",
        ")\n",
        "\n",
        "# a demonstration of how to feed an input value to the model\n",
        "dummy_in = next(iter(input_generator))\n",
        "_ = model(**dummy_in)"
      ],
      "metadata": {
        "id": "LJAFUiCFLLYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the mase graph and initialize node metadata\n",
        "mg = MaseGraph(model=model)"
      ],
      "metadata": {
        "id": "LgSdEBNBLN_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis pass: it does not change the graph\n",
        "\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
        "mg, _ = add_software_metadata_analysis_pass(mg, None)"
      ],
      "metadata": {
        "id": "WnqozIzjLOlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# report graph is an analysis pass that shows you the detailed information in the graph\n",
        "from chop.passes.graph import report_graph_analysis_pass\n",
        "_ = report_graph_analysis_pass(mg)"
      ],
      "metadata": {
        "id": "yjFhdjllLSaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Profile Statistics Pass\n",
        "pass_args = {\n",
        "    \"by\": \"type\",                                                            # collect statistics by node name\n",
        "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
        "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
        "    \"weight_statistics\": {\n",
        "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
        "    },\n",
        "    \"activation_statistics\": {\n",
        "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
        "    },\n",
        "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
        "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
        "}\n",
        "\n",
        "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
        "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"
      ],
      "metadata": {
        "id": "Hy5Q3sMnLaxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Pass: Quantization\n",
        "\n",
        "pass_args = {\n",
        "    \"by\": \"type\",\n",
        "    \"default\": {\"config\": {\"name\": None}},\n",
        "    \"linear\": {\n",
        "        \"config\": {\n",
        "            \"name\": \"integer\",\n",
        "            # data\n",
        "            \"data_in_width\": 8,\n",
        "            \"data_in_frac_width\": 4,\n",
        "            # weight\n",
        "            \"weight_width\": 8,\n",
        "            \"weight_frac_width\": 4,\n",
        "            # bias\n",
        "            \"bias_width\": 8,\n",
        "            \"bias_frac_width\": 4,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "from chop.passes.graph.transforms import (\n",
        "    quantize_transform_pass,\n",
        "    summarize_quantization_analysis_pass,\n",
        ")\n",
        "from chop.ir.graph.mase_graph import MaseGraph\n",
        "\n",
        "\n",
        "ori_mg = MaseGraph(model=model)\n",
        "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
        "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
        "\n",
        "mg, _ = quantize_transform_pass(mg, pass_args)\n",
        "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
      ],
      "metadata": {
        "id": "KsdlvssILwk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2 Question 4\n",
        "\n",
        "\n",
        "# from chop.passes.graph.utils\n",
        "\n",
        "def get_mase_op(node):\n",
        "    return node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"]\n",
        "\n",
        "def get_mase_type(node):\n",
        "    return node.meta[\"mase\"].parameters[\"common\"][\"mase_type\"]\n",
        "\n",
        "def get_node_actual_target(node):\n",
        "  \"\"\"\n",
        "  return the actual target of the node\n",
        "  - for \"call_module\": return the torch.nn.Module instance\n",
        "  - for \"call_function\": return the function\n",
        "  - for others: return the node.target\n",
        "  \"\"\"\n",
        "  if node.op == \"call_module\":\n",
        "      return node.meta[\"mase\"].module\n",
        "  elif node.op == \"call_function\":\n",
        "      return node.target\n",
        "  else:\n",
        "      return node.target\n",
        "\n",
        "def compare_graph_nodes(ori_mg, mg):\n",
        "  # Traverse the graph\n",
        "  for transformed_mg_node, original_ms_node in zip(mg.fx_graph.nodes, ori_mg.fx_graph.nodes):\n",
        "\n",
        "    # Check if the types of the actual targets of the nodes are different\n",
        "    if (type(get_node_actual_target(transformed_mg_node)) != type(get_node_actual_target(original_ms_node))):\n",
        "\n",
        "        # Get the types of the original and transformed nodes\n",
        "        original_node_type = type(get_node_actual_target(original_ms_node))\n",
        "        quantized_node_type = type(get_node_actual_target(transformed_mg_node))\n",
        "\n",
        "        # Same for both original and transformed MaseGraph\n",
        "        print(f' Node Name: {transformed_mg_node.name}')\n",
        "        print(f' Node Mase Type: {get_mase_type(transformed_mg_node)}')\n",
        "        print(f' Node Mase Operation: {get_mase_op(transformed_mg_node)}')\n",
        "        # Module difference\n",
        "        print(f' Original Module: {original_node_type}')\n",
        "        print(f' New Module: {quantized_node_type}\\n')\n",
        "\n",
        "# Example usage\n",
        "compare_graph_nodes(ori_mg, mg)\n"
      ],
      "metadata": {
        "id": "M1ltbg8mK7W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2 Question 5\n",
        "\n",
        "model_name = 'jsc-less-tiny'\n",
        "\n",
        "# Set Up the Model\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tinyX10/software/training_ckpts/best_ep10_bs256.ckpt\"\n",
        "model_info = get_model_info(model_name)\n",
        "model = get_model(\n",
        "    model_name,\n",
        "    task=\"cls\",\n",
        "    dataset_info=data_module.dataset_info,\n",
        "    pretrained=False)\n",
        "\n",
        "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
        "\n",
        "# Get Dummy Data In\n",
        "# get the input generator\n",
        "input_generator = InputGenerator(\n",
        "    data_module=data_module,\n",
        "    model_info=model_info,\n",
        "    task=\"cls\",\n",
        "    which_dataloader=\"train\",\n",
        ")\n",
        "\n",
        "# a demonstration of how to feed an input value to the model\n",
        "dummy_in = next(iter(input_generator))\n",
        "_ = model(**dummy_in)\n",
        "\n",
        "# generate the mase graph and initialize node metadata\n",
        "mg = MaseGraph(model=model)\n",
        "\n",
        "# Analysis pass: it does not change the graph\n",
        "\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
        "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
        "\n",
        "\n",
        "# Transform Pass: Quantization\n",
        "\n",
        "pass_args = {\n",
        "    \"by\": \"type\",\n",
        "    \"default\": {\"config\": {\"name\": None}},\n",
        "    \"linear\": {\n",
        "        \"config\": {\n",
        "            \"name\": \"integer\",\n",
        "            # data\n",
        "            \"data_in_width\": 8,\n",
        "            \"data_in_frac_width\": 4,\n",
        "            # weight\n",
        "            \"weight_width\": 8,\n",
        "            \"weight_frac_width\": 4,\n",
        "            # bias\n",
        "            \"bias_width\": 8,\n",
        "            \"bias_frac_width\": 4,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "from chop.passes.graph.transforms import (\n",
        "    quantize_transform_pass,\n",
        "    summarize_quantization_analysis_pass,\n",
        ")\n",
        "from chop.ir.graph.mase_graph import MaseGraph\n",
        "\n",
        "\n",
        "ori_mg = MaseGraph(model=model)\n",
        "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
        "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
        "\n",
        "mg, _ = quantize_transform_pass(mg, pass_args)\n",
        "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
      ],
      "metadata": {
        "id": "2C2gbYUZLVmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2 Question 6\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Initialize an empty list to store node comparison data\n",
        "comparison_data = []\n",
        "comparison_weight = []\n",
        "comparison_bias = []\n",
        "\n",
        "for node_ori, node_quant in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
        "    # Extracting original and quantized model information\n",
        "    try:\n",
        "      row_data = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          node_ori.meta['mase'].parameters['common']['args']['data_in_0'].get('type', 'N/A'),\n",
        "          node_ori.meta['mase'].parameters['common']['args']['data_in_0'].get('precision', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['data_in_0'].get('type', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['data_in_0'].get('precision', 'N/A'),\n",
        "      ]\n",
        "      row_weight = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          node_ori.meta['mase'].parameters['common']['args']['weight'].get('type', 'N/A'),\n",
        "          node_ori.meta['mase'].parameters['common']['args']['weight'].get('precision', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['weight'].get('type', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['weight'].get('precision', 'N/A'),\n",
        "      ]\n",
        "      row_bias = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          node_ori.meta['mase'].parameters['common']['args']['bias'].get('type', 'N/A'),\n",
        "          node_ori.meta['mase'].parameters['common']['args']['bias'].get('precision', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['bias'].get('type', 'N/A'),\n",
        "          node_quant.meta['mase'].parameters['common']['args']['bias'].get('precision', 'N/A')\n",
        "      ]\n",
        "    except:\n",
        "      row_data = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "      ]\n",
        "      row_weight = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "      ]\n",
        "      row_bias = [\n",
        "          node_ori.meta['mase'].node,\n",
        "          node_ori.meta['mase'].parameters['common']['mase_op'],\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "          \"N/A\",\n",
        "      ]\n",
        "    comparison_data.append(row_data)\n",
        "    comparison_weight.append(row_weight)\n",
        "    comparison_bias.append(row_bias)\n",
        "\n",
        "headers_data = [\"Node\", \"MASE OP\", \"Original Data DType\", \"Original Data Precision\", \"Quantized Data DType\", \"Quantized Data Precision\"]\n",
        "headers_weight = [\"Node\", \"MASE OP\", \"Original Weight DType\", \"Original Weight Precision\", \"Quantized Weight DType\", \"Quantized Weight Precision\"]\n",
        "headers_bias = [\"Node\", \"MASE OP\", \"Original Bias DType\", \"Original Bias Precision\", \"Quantized Bias DType\", \"Quantized Bias Precision\"]\n",
        "\n",
        "table_data = tabulate(comparison_data, headers=headers_data, tablefmt=\"grid\")\n",
        "print(table_data)\n",
        "print(\"\\n\")\n",
        "table_weight = tabulate(comparison_weight, headers=headers_weight, tablefmt=\"grid\")\n",
        "print(table_weight)\n",
        "print(\"\\n\")\n",
        "table_bias = tabulate(comparison_bias, headers=headers_bias, tablefmt=\"grid\")\n",
        "print(table_bias)"
      ],
      "metadata": {
        "id": "Wg3Z_HvsQCeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L2Q6 - continued\n",
        "import pandas as pd\n",
        "\n",
        "for ori_node, quant_node in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
        "  if type(quant_node.meta['mase'].module).__name__ == \"LinearInteger\":\n",
        "    print(f\"Original Weights - Layer {quant_node.meta['mase'].module}\")\n",
        "    print(f\"\\t{quant_node.meta['mase']['common']['args']['weight']}\")\n",
        "    print(f\"Quantized Weights - Layer {quant_node.meta['mase'].module}\")\n",
        "    print(f\"\\t{quant_node.meta['mase'].module.w_quantizer(quant_node.meta['mase'].module.weight)}\")\n",
        ""
      ],
      "metadata": {
        "id": "9KOYAJQdmSIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "tensor_original = quant_node.meta['mase']['common']['args']['weight']['value'].detach()\n",
        "tensor_quantized = quant_node.meta['mase'].module.w_quantizer(quant_node.meta['mase'].module.weight).detach()\n",
        "\n",
        "\n",
        "flat_tensor_original = tensor_original.flatten()\n",
        "flat_tensor_quantized = tensor_quantized.flatten()\n",
        "\n",
        "# Plot histograms\n",
        "plt.hist(flat_tensor_original.numpy(), bins=50, alpha=0.5, label='Original Weights')\n",
        "plt.hist(flat_tensor_quantized.numpy(), bins=50, alpha=0.5, label='Quantized Weights')\n",
        "plt.xlabel('Value', fontsize=16)\n",
        "plt.ylabel('Frequency', fontsize=16)\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Histogram Comparison: Original vs Quantized Weights')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VgSTY_JUvABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2 Question 7\n",
        "\n",
        "!./ch transform --config configs/examples/jsc_less_tiny_by_type_quantize_L2Q7.toml --task cls --accelerator='cpu'"
      ],
      "metadata": {
        "id": "jsYZnonVV6kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#___\n",
        "# Lab 2 - Optional: Write pass to count FLOPs and BitOPs\n",
        "#___\n",
        "\n",
        "# from chop.passes.graph.analysis.flop_estimator.calc_modules import calculate_modules\n",
        "\n",
        "import torch\n",
        "\n",
        "def get_multipliers(weight=None, bias=None, data=None):\n",
        "    if weight is not None:\n",
        "        if weight.dtype == torch.float32:\n",
        "          weight_multiplier = 32\n",
        "        elif weight.dtype == torch.float16:\n",
        "          weight_multiplier = 16\n",
        "        else:\n",
        "          weight_multiplier = 8\n",
        "    else:\n",
        "        weight_multiplier = 1\n",
        "\n",
        "    if bias is not None:\n",
        "        if bias.dtype == torch.float32:\n",
        "          bias_multiplier = 32\n",
        "        elif bias.dtype == torch.float16:\n",
        "          bias_multiplier = 16\n",
        "        else:\n",
        "          bias_multiplier = 8\n",
        "    else:\n",
        "        bias_multiplier = 1\n",
        "\n",
        "    if data is not None:\n",
        "        if data == torch.float32:\n",
        "          data_multiplier = 32\n",
        "        elif data == torch.float16:\n",
        "          data_multiplier = 16\n",
        "        else:\n",
        "          data_multiplier = 8\n",
        "    else:\n",
        "        data_multiplier = 1\n",
        "\n",
        "    return {\n",
        "        \"weight_multiplier\": weight_multiplier,\n",
        "        \"bias_multiplier\": bias_multiplier,\n",
        "        \"data_multiplier\": data_multiplier,\n",
        "    }\n",
        "\n",
        "def calculate_modules(module, node, in_data, out_data, include_bias=True):\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "        # One computation per weight, for each batch element.\n",
        "\n",
        "        assert len(in_data) == 1\n",
        "        batch = in_data[0].numel() / in_data[0].shape[-1]\n",
        "\n",
        "        multipliers = {\n",
        "            \"weight_multiplier\" : node.meta['mase'].parameters['common']['args']['weight']['precision'][0],\n",
        "            \"bias_multiplier\" : node.meta['mase'].parameters['common']['args']['bias']['precision'][0],\n",
        "            \"data_multiplier\" : node.meta['mase'].parameters['common']['args']['data_in_0']['precision'][0]\n",
        "        }\n",
        "\n",
        "        if include_bias:\n",
        "          #multipliers = get_multipliers(weight=module.weight, bias=module.bias, data=in_data[0])\n",
        "\n",
        "          computations = ( module.weight.numel() + module.bias.numel() ) * batch\n",
        "          bitops = ( (module.weight.numel() * multipliers['weight_multiplier']) + (module.bias.numel() * multipliers['bias_multiplier']) ) * batch * multipliers['data_multiplier']\n",
        "          backward_computations = module.weight.numel() * batch * 2\n",
        "        else:\n",
        "          #multipliers = get_multipliers(weight=module.weight, data=in_data[0])\n",
        "\n",
        "          computations = module.weight.numel() * batch\n",
        "          bitops = (module.weight.numel() * multipliers['weight_multiplier']) * batch * multipliers['data_multiplier']\n",
        "          backward_computations = module.weight.numel() * batch * 2\n",
        "\n",
        "        input_size = in_data[0].numel()\n",
        "        output_size = out_data[0].numel()\n",
        "        return {\n",
        "            \"total_parameters\": module.weight.numel(),\n",
        "            \"bitops\": bitops,\n",
        "            \"computations\": computations,\n",
        "            \"backward_computations\": backward_computations,\n",
        "            \"input_buffer_size\": input_size,\n",
        "            \"output_buffer_size\": output_size,\n",
        "        }\n",
        "\n",
        "    elif isinstance(module, torch.nn.modules.activation.ReLU) or isinstance(\n",
        "        module, torch.nn.modules.activation.ReLU6\n",
        "    ):\n",
        "        multipliers = get_multipliers(data=in_data[0])\n",
        "        # ReLU does a single negation check\n",
        "        return {\n",
        "            \"total_parameters\": 0,\n",
        "            \"computations\": in_data[0].numel(),\n",
        "            \"bitops\": in_data[0].numel() * multipliers['data_multiplier'],\n",
        "            \"backward_computations\": in_data[0].numel(),\n",
        "            \"input_buffer_size\": in_data[0].numel(),\n",
        "            \"output_buffer_size\": out_data[0].numel(),\n",
        "        }\n",
        "\n",
        "    elif isinstance(module, torch.nn.LayerNorm):\n",
        "        multipliers = {\n",
        "            \"data_multiplier\" : node.meta['mase'].parameters['common']['args']['data_in_0']['precision'][0]\n",
        "        }\n",
        "\n",
        "        #multipliers = get_multipliers(data=in_data[0])\n",
        "\n",
        "        computations = in_data[0].numel() * 5\n",
        "\n",
        "        return {\n",
        "            \"total_parameters\": 0,\n",
        "            \"computations\": computations,\n",
        "            \"bitops\": computations * multipliers['data_multiplier'],\n",
        "            \"backward_computations\": in_data[0].numel() * 5,\n",
        "            \"input_buffer_size\": in_data[0].numel(),\n",
        "            \"output_buffer_size\": out_data[0].numel(),\n",
        "        }\n",
        "\n",
        "    elif isinstance(module, torch.nn.modules.batchnorm.BatchNorm1d):\n",
        "        multipliers = {\n",
        "            \"data_multiplier\" : node.meta['mase'].parameters['common']['args']['data_in_0']['precision'][0]\n",
        "        }\n",
        "\n",
        "        #multipliers = get_multipliers(data=in_data[0])\n",
        "\n",
        "        # Accesses to E[x] and Var[x] (all channel size)\n",
        "        total_parameters = 2 * module.num_features\n",
        "        # (x-running_mean)/running variance\n",
        "        # multiply by gamma and beta addition\n",
        "        computations = 4 * in_data[0].numel()\n",
        "        backward_computations = 4 * in_data[0].numel()\n",
        "\n",
        "        return {\n",
        "            \"total_parameters\": total_parameters,\n",
        "            \"computations\": computations,\n",
        "            \"bitops\": computations * multipliers['data_multiplier'],\n",
        "            \"backward_computations\": backward_computations,\n",
        "            \"input_buffer_size\": in_data[0].numel(),\n",
        "            \"output_buffer_size\": out_data[0].numel(),\n",
        "        }\n",
        "    else:\n",
        "        print(\"Unsupported module type for analysis:\", type(module))\n",
        "\n",
        "\n",
        "model_name = 'jsc-less-tiny'\n",
        "\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tinyX10/software/training_ckpts/best_ep10_bs256.ckpt\"\n",
        "model_info = get_model_info(model_name)\n",
        "model = get_model(\n",
        "    model_name,\n",
        "    task=\"cls\",\n",
        "    dataset_info=data_module.dataset_info,\n",
        "    pretrained=False)\n",
        "\n",
        "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
        "\n",
        "input_generator = InputGenerator(\n",
        "    data_module=data_module,\n",
        "    model_info=model_info,\n",
        "    task=\"cls\",\n",
        "    which_dataloader=\"train\",\n",
        ")\n",
        "\n",
        "dummy_in = next(iter(input_generator))\n",
        "_ = model(**dummy_in)\n",
        "\n",
        "mg = MaseGraph(model=model)\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
        "\n",
        "\n",
        "from chop.passes.graph.utils import get_node_actual_target\n",
        "#from chop.passes.graph.analysis.flop_estimator.calculator.calc_modules import calculate_modules # modified to account for BatchNorm1d as well\n",
        "\n",
        "def computational_complexity_report_pass(graph, include_bias=True):\n",
        "  store_data = {}\n",
        "  for node in graph.fx_graph.nodes:\n",
        "    try:\n",
        "      in_data = (node.meta['mase'].parameters['common']['args']['data_in_0']['value'],)\n",
        "    except KeyError:\n",
        "      in_data = (None,)\n",
        "    out_data = (node.meta['mase'].parameters['common']['results']['data_out_0']['value'],)\n",
        "\n",
        "\n",
        "    module = get_node_actual_target(node)\n",
        "    if isinstance(module, torch.nn.Module):\n",
        "      data = calculate_modules(module, node, in_data, out_data, include_bias)\n",
        "\n",
        "      store_data[module] = data\n",
        "\n",
        "  count_flops = 0\n",
        "  count_bitops = 0\n",
        "  for key in store_data.keys():\n",
        "    count_flops += store_data[key]['computations']\n",
        "    count_bitops += store_data[key]['bitops']\n",
        "  print(f\"Total FLOPs: {count_flops}; Total BitOPs: {count_bitops}\")\n",
        "  return {\n",
        "      \"flops\": count_flops,\n",
        "      \"bitops\": count_bitops,\n",
        "          }\n",
        "\n",
        "complexity_metrics = computational_complexity_report_pass(mg, include_bias=True) # dict; keys: flops, bitops"
      ],
      "metadata": {
        "id": "3mJTpxnmlVG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "# Lab 3"
      ],
      "metadata": {
        "id": "HlJVwTGQLjmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pprint import pprint as pp\n",
        "\n",
        "# figure out the correct path\n",
        "machop_path = Path(\".\").resolve().parent /\"machop\"\n",
        "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
        "sys.path.append(str(machop_path))\n",
        "\n",
        "from chop.dataset import MaseDataModule, get_dataset_info\n",
        "from chop.tools.logger import get_logger\n",
        "\n",
        "from chop.passes.graph.analysis import (\n",
        "    report_node_meta_param_analysis_pass,\n",
        "    profile_statistics_analysis_pass,\n",
        ")\n",
        "from chop.passes.graph import (\n",
        "    add_common_metadata_analysis_pass,\n",
        "    init_metadata_analysis_pass,\n",
        "    add_software_metadata_analysis_pass,\n",
        ")\n",
        "from chop.tools.get_input import InputGenerator\n",
        "from chop.ir.graph.mase_graph import MaseGraph\n",
        "\n",
        "from chop.models import get_model_info, get_model\n",
        "\n",
        "\n",
        "logger = get_logger(\"chop\")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "batch_size = 8\n",
        "model_name = \"jsc-less-tiny\"\n",
        "dataset_name = \"jsc\"\n",
        "\n",
        "\n",
        "data_module = MaseDataModule(\n",
        "    name=dataset_name,\n",
        "    batch_size=batch_size,\n",
        "    model_name=model_name,\n",
        "    num_workers=0,\n",
        "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
        ")\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/jsc_tinyX10/software/training_ckpts/best_ep10_bs256.ckpt\"\n",
        "model_info = get_model_info(model_name)\n",
        "model = get_model(\n",
        "    model_name,\n",
        "    task=\"cls\",\n",
        "    dataset_info=data_module.dataset_info,\n",
        "    pretrained=False)\n",
        "\n",
        "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
        "\n",
        "input_generator = InputGenerator(\n",
        "    data_module=data_module,\n",
        "    model_info=model_info,\n",
        "    task=\"cls\",\n",
        "    which_dataloader=\"train\",\n",
        ")\n",
        "\n",
        "dummy_in = next(iter(input_generator))\n",
        "_ = model(**dummy_in)\n",
        "\n",
        "mg = MaseGraph(model=model)\n",
        "\n",
        "\n",
        "# Formulate Search Space\n",
        "\n",
        "pass_args = {\n",
        "\"by\": \"type\",\n",
        "\"default\": {\"config\": {\"name\": None}},\n",
        "\"linear\": {\n",
        "        \"config\": {\n",
        "            \"name\": \"integer\",\n",
        "            # data\n",
        "            \"data_in_width\": 8,\n",
        "            \"data_in_frac_width\": 4,\n",
        "            # weight\n",
        "            \"weight_width\": 8,\n",
        "            \"weight_frac_width\": 4,\n",
        "            # bias\n",
        "            \"bias_width\": 8,\n",
        "            \"bias_frac_width\": 4,\n",
        "        }\n",
        "},}\n",
        "\n",
        "import copy\n",
        "# build a search space\n",
        "data_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
        "w_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
        "search_spaces = []\n",
        "for d_config in data_in_frac_widths:\n",
        "    for w_config in w_in_frac_widths:\n",
        "        pass_args['linear']['config']['data_in_width'] = d_config[0]\n",
        "        pass_args['linear']['config']['data_in_frac_width'] = d_config[1]\n",
        "        pass_args['linear']['config']['weight_width'] = w_config[0]\n",
        "        pass_args['linear']['config']['weight_frac_width'] = w_config[1]\n",
        "        # dict.copy() and dict(dict) only perform shallow copies\n",
        "        # in fact, only primitive data types in python are doing implicit copy when a = b happens\n",
        "        search_spaces.append(copy.deepcopy(pass_args))\n",
        "\n",
        "# Grid Search\n",
        "\n",
        "import torch\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
        "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=5)\n",
        "num_batchs = 100\n",
        "\n",
        "def measure_throughput(model, data_loader, num_batchs):\n",
        "    model.eval()\n",
        "    total_inferences = 0\n",
        "    start_time = time.time()\n",
        "    j = 0\n",
        "    for input in data_loader:\n",
        "      xs, ys = inputs\n",
        "\n",
        "      model(xs)\n",
        "      total_inferences += len(xs)\n",
        "\n",
        "      if j > num_batchs:\n",
        "          break\n",
        "      j += 1\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    throughput = total_inferences / elapsed_time\n",
        "\n",
        "    return throughput\n",
        "\n",
        "recorded_accs = []\n",
        "recorded_losses = []\n",
        "recorded_inference_time = []\n",
        "recorded_flops = []\n",
        "recorded_bitops = []\n",
        "recorded_throughput = []\n",
        "for i, config in enumerate(search_spaces):\n",
        "  mg_quantized, _ = quantize_transform_pass(mg, config)\n",
        "  j = 0\n",
        "\n",
        "  # this is the inner loop, where we also call it as a runner.\n",
        "  acc_avg, loss_avg = 0, 0\n",
        "  inference_time_avg = 0\n",
        "  accs, losses = [], []\n",
        "  inference_time = []\n",
        "  for inputs in data_module.train_dataloader(): #use test_dataloader?\n",
        "      xs, ys = inputs\n",
        "\n",
        "      starting_time = time.time()\n",
        "      preds = mg_quantized.model(xs)\n",
        "      inference_time.append(time.time() - starting_time)\n",
        "\n",
        "      loss = torch.nn.functional.cross_entropy(preds, ys)\n",
        "      acc = metric(preds, ys)\n",
        "      accs.append(acc.item())\n",
        "      losses.append(loss)\n",
        "      if j > num_batchs:\n",
        "          break\n",
        "      j += 1\n",
        "\n",
        "  throughput = measure_throughput(mg_quantized.model, data_module.train_dataloader(), num_batchs)\n",
        "  acc_avg = sum(accs) / len(accs)\n",
        "  loss_avg = sum(losses) / len(losses)\n",
        "  inference_time_avg = sum(inference_time) / len(inference_time)\n",
        "  recorded_accs.append(np.round(acc_avg, 2))\n",
        "  recorded_losses.append(loss_avg)\n",
        "\n",
        "  recorded_inference_time.append(np.round(inference_time_avg*1000, 2))\n",
        "\n",
        "  recorded_throughput.append(np.round(throughput))\n",
        "\n",
        "  complexity_metrics = computational_complexity_report_pass(mg_quantized)\n",
        "  recorded_flops.append(np.round(complexity_metrics['flops']))\n",
        "  recorded_bitops.append(np.round(complexity_metrics['bitops']))\n",
        "  #recorded_flops.append(flops)\n",
        "\n",
        "for i, (accuracy, inference_time, flops, bitops, throughput, search_space) in enumerate(zip(recorded_accs, recorded_inference_time, recorded_flops, recorded_bitops, recorded_throughput, search_spaces)):\n",
        "  print(f\"Trial {i}\")\n",
        "  print(f\"\\tAccuracy: {accuracy} | Inference Time: {inference_time} | FLOPs: {flops} | BitOPs: {bitops} | Throughput: {throughput}\")\n",
        "  print(f\"\\t{search_space['linear']['config']}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "4PIqnH-ORzkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the lists into 4x4 matrices\n",
        "acc_matrix = np.array(recorded_accs).reshape(4, 4)\n",
        "time_matrix = np.array(recorded_inference_time).reshape(4, 4)\n",
        "bitops_matrix = np.array(recorded_bitops).reshape(4, 4)\n",
        "throughput_matrix = np.array(recorded_throughput).reshape(4, 4)\n",
        "\n",
        "# Define the labels for the axes based on your configurations\n",
        "data_in_labels = ['(16,8)', '(8,6)', '(8,4)', '(4,2)']\n",
        "w_in_labels = ['(16,8)', '(8,6)', '(8,4)', '(4,2)']\n",
        "\n",
        "# Set up the matplotlib figure for 4 subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Titles for each subplot\n",
        "titles = ['Accuracy', 'Inference Time', 'BitOPs', 'Throughput']\n",
        "\n",
        "# Data for each subplot\n",
        "data_matrices = [acc_matrix, time_matrix, bitops_matrix, throughput_matrix]\n",
        "\n",
        "# Customization for each heatmap\n",
        "for ax, data_matrix, title in zip(axs.flat, data_matrices, titles):\n",
        "    sns.heatmap(data_matrix, annot=True, fmt=\".2f\", cmap='Blues',\n",
        "                xticklabels=data_in_labels, yticklabels=w_in_labels,\n",
        "                ax=ax)\n",
        "    ax.set_title(title, fontsize=16, weight='bold')\n",
        "    ax.set_xlabel('Data Input Widths', fontsize=14, weight='bold')\n",
        "    ax.set_ylabel('Weight Widths', fontsize=14, weight='bold')\n",
        "    ax.xaxis.set_tick_params(rotation=45, labelsize=12)\n",
        "    ax.yaxis.set_tick_params(rotation=45, labelsize=12)\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XFIHfg4Rjryt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 3 Question 4\n",
        "\n",
        "!./ch search --load-type \"pl\" --config \"configs/examples/jsc_less_tiny_by_name_search_L3Q4_TPE.toml\" --load \"../mase_output/jsc_tinyX10/software/training_ckpts/best_ep10_bs256.ckpt\" --project-dir \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/searches_output/L3Q4\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ZOeNJpY7Kdjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/searches_output/L3Q4/jsc_tinyX10/software/search_ckpts/best_results.json') as json_file:\n",
        "    best_results = json.load(json_file)\n",
        "\n",
        "print(f\"Best Trial: {best_results['best_trial']} | Best Accuracy: {best_results['acc']}\")\n",
        "print(f\"Best Configuration:\")\n",
        "print(best_results['config'])\n",
        "'''"
      ],
      "metadata": {
        "id": "T5p0Go8LLh3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/searches_output/L3Q4/jsc_tinyX10/software/tensorboard/lightning_logs\n"
      ],
      "metadata": {
        "id": "yQPtkXlepHo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "# Lab 4"
      ],
      "metadata": {
        "id": "SZYZQmad6kWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pprint import pprint as pp\n",
        "\n",
        "\n",
        "# figure out the correct path\n",
        "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
        "#assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
        "#sys.path.append(str(machop_path))\n",
        "\n",
        "from chop.dataset import MaseDataModule, get_dataset_info\n",
        "from chop.tools.logger import set_logging_verbosity, get_logger\n",
        "\n",
        "from chop.passes.graph.analysis import (\n",
        "    report_node_meta_param_analysis_pass,\n",
        "    profile_statistics_analysis_pass,\n",
        ")\n",
        "from chop.passes.graph import (\n",
        "    add_common_metadata_analysis_pass,\n",
        "    init_metadata_analysis_pass,\n",
        "    add_software_metadata_analysis_pass,\n",
        ")\n",
        "from chop.tools.get_input import InputGenerator\n",
        "from chop.ir.graph.mase_graph import MaseGraph\n",
        "\n",
        "from chop.models import get_model_info, get_model\n",
        "\n",
        "set_logging_verbosity(\"info\")\n",
        "\n",
        "logger = get_logger(\"chop\")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "batch_size = 8\n",
        "model_name = \"jsc-tiny\"\n",
        "dataset_name = \"jsc\"\n",
        "\n",
        "model_name = \"jsc-tiny\"\n",
        "\n",
        "data_module = MaseDataModule(\n",
        "    name=dataset_name,\n",
        "    batch_size=batch_size,\n",
        "    model_name=model_name,\n",
        "    num_workers=0,\n",
        ")\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "model_info = get_model_info(model_name)\n",
        "dataset_info = get_dataset_info(dataset_name)\n",
        "\n",
        "input_generator = InputGenerator(\n",
        "    data_module=data_module,\n",
        "    model_info=model_info,\n",
        "    task=\"cls\",\n",
        "    which_dataloader=\"train\",\n",
        ")\n",
        "\n",
        "dummy_in = {\"x\": next(iter(data_module.train_dataloader()))[0]}\n",
        "\n",
        "from torch import nn\n",
        "from chop.passes.graph.utils import get_parent_name\n",
        "\n",
        "# define a new model\n",
        "class JSC_Three_Linear_Layers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(JSC_Three_Linear_Layers, self).__init__()\n",
        "        self.seq_blocks = nn.Sequential(\n",
        "            nn.BatchNorm1d(16),  # 0\n",
        "            nn.ReLU(16),  # 1\n",
        "            nn.Linear(16, 16),  # linear  2\n",
        "            nn.Linear(16, 16),  # linear  3\n",
        "            nn.Linear(16, 5),   # linear  4\n",
        "            nn.ReLU(5),  # 5\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq_blocks(x)\n",
        "\n",
        "model = JSC_Three_Linear_Layers()\n",
        "\n",
        "# generate the mase graph and initialize node metadata\n",
        "mg = MaseGraph(model=model)\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "\n",
        "def instantiate_linear(in_features, out_features, bias):\n",
        "    if bias is not None:\n",
        "        bias = True\n",
        "    return nn.Linear(\n",
        "        in_features=in_features,\n",
        "        out_features=out_features,\n",
        "        bias=bias)\n",
        "\n",
        "def redefine_linear_transform_pass(graph, pass_args=None):\n",
        "    main_config = pass_args.pop('config')\n",
        "    default = main_config.pop('default', None)\n",
        "    if default is None:\n",
        "        raise ValueError(f\"default value must be provided.\")\n",
        "    i = 0\n",
        "    for node in graph.fx_graph.nodes:\n",
        "        i += 1\n",
        "        # if node name is not matched, it won't be tracked\n",
        "        config = main_config.get(node.name, default)['config']\n",
        "        name = config.get(\"name\", None)\n",
        "        if name is not None:\n",
        "            ori_module = graph.modules[node.target]\n",
        "            in_features = ori_module.in_features\n",
        "            out_features = ori_module.out_features\n",
        "            bias = ori_module.bias\n",
        "            if name == \"output_only\":\n",
        "                out_features = out_features * config[\"channel_multiplier\"]\n",
        "            elif name == \"both\":\n",
        "                in_features = in_features * config[\"channel_multiplier\"]\n",
        "                out_features = out_features * config[\"channel_multiplier\"]\n",
        "            elif name == \"input_only\":\n",
        "                in_features = in_features * config[\"channel_multiplier\"]\n",
        "            new_module = instantiate_linear(in_features, out_features, bias)\n",
        "            parent_name, name = get_parent_name(node.target)\n",
        "            setattr(graph.modules[parent_name], name, new_module)\n",
        "    return graph, {}\n",
        "\n",
        "\n",
        "pass_config = {\n",
        "\"by\": \"name\",\n",
        "\"default\": {\"config\": {\"name\": None}},\n",
        "\"seq_blocks_2\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"output_only\",\n",
        "        # weight\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_3\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"both\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_4\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"input_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "# this performs the architecture transformation based on the config\n",
        "# mg, _ = redefine_linear_transform_pass(\n",
        "#     graph=mg, pass_args={\"config\": pass_config})\n",
        "\n",
        "# define a new model\n",
        "class JSC_Three_Linear_Layers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(JSC_Three_Linear_Layers, self).__init__()\n",
        "        self.seq_blocks = nn.Sequential(\n",
        "            nn.BatchNorm1d(16),  # 0\n",
        "            nn.ReLU(16),  # 1\n",
        "            nn.Linear(16, 16),  # linear seq_2\n",
        "            nn.ReLU(16),  # 3\n",
        "            nn.Linear(16, 16),  # linear seq_4\n",
        "            nn.ReLU(16),  # 5\n",
        "            nn.Linear(16, 5),  # linear seq_6\n",
        "            nn.ReLU(5),  # 7\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq_blocks(x)"
      ],
      "metadata": {
        "id": "FVxa52cT6Hoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4 Question 1\n",
        "\n",
        "\n",
        "model = JSC_Three_Linear_Layers()\n",
        "\n",
        "mg = MaseGraph(model=model)\n",
        "mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "\n",
        "print(\"Original Graph:\")\n",
        "for block in mg.model.seq_blocks._modules:\n",
        "  print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n",
        "\n",
        "\n",
        "pass_config = {\n",
        "\"by\": \"name\",\n",
        "\"default\": {\"config\": {\"name\": None}},\n",
        "\"seq_blocks_2\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"output_only\",\n",
        "        # weight\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_4\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"both\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_6\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"input_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "mg, _ = redefine_linear_transform_pass(\n",
        "    graph=mg, pass_args={\"config\": pass_config})\n",
        "\n",
        "print(\"Expanded Graph:\")\n",
        "for block in mg.model.seq_blocks._modules:\n",
        "  print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n"
      ],
      "metadata": {
        "id": "DjQUauc48UNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4 Question 2\n",
        "\n",
        "import torch\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "from chop.actions.train import train\n",
        "from chop.actions.test import test\n",
        "\n",
        "### Define Search Space\n",
        "\n",
        "pass_config = {\n",
        "\"by\": \"name\",\n",
        "\"default\": {\"config\": {\"name\": None}},\n",
        "\"seq_blocks_2\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"output_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_4\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"both\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_6\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"input_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "channel_multipliers = [1, 2, 3, 4]\n",
        "\n",
        "# channel_multiplier_block2 = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
        "# channel_multiplier_block4 = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
        "# channel_multiplier_block6 = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
        "\n",
        "# define the search space\n",
        "search_spaces = []\n",
        "for channel_multiplier in channel_multipliers:\n",
        "  pass_config['seq_blocks_2']['config']['channel_multiplier'] = channel_multiplier\n",
        "  pass_config['seq_blocks_4']['config']['channel_multiplier'] = channel_multiplier\n",
        "  pass_config['seq_blocks_6']['config']['channel_multiplier'] = channel_multiplier\n",
        "  search_spaces.append(copy.deepcopy(pass_config))\n",
        "\n",
        "# define the metric to maximize in search\n",
        "metric = MulticlassAccuracy(num_classes=5)\n",
        "batch_size = 128\n",
        "\n",
        "# define model, dataset, task\n",
        "model_name = \"jsc-three-linear-layers\"\n",
        "dataset_name = \"jsc\"\n",
        "task = \"cls\"\n",
        "\n",
        "model_info = get_model_info(model_name)\n",
        "dataset_info = get_dataset_info(dataset_name)\n",
        "\n",
        "data_module = MaseDataModule(\n",
        "    name=dataset_name,\n",
        "    batch_size=batch_size,\n",
        "    model_name=model_name,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "data_module.prepare_data()\n",
        "data_module.setup()\n",
        "\n",
        "# trainer args required by the train function; use only the default arguments for this search (except max epochs: 20 -> 5)\n",
        "plt_trainer_args = {\n",
        "    \"max_epochs\": 5,\n",
        "    \"max_steps\": -1,\n",
        "    \"devices\": 1,\n",
        "    \"num_nodes\": 1,\n",
        "    \"accelerator\": 'gpu',\n",
        "    \"strategy\": 'auto',\n",
        "    \"fast_dev_run\": False,\n",
        "    \"precision\": \"16-mixed\",\n",
        "    \"accumulate_grad_batches\": 1,\n",
        "    \"log_every_n_steps\": 50,\n",
        "}\n",
        "\n",
        "\n",
        "def brute_force(search_spaces):\n",
        "\n",
        "  best_acc = 0\n",
        "  best_multiplier = 1\n",
        "\n",
        "  recorded_accs = []\n",
        "  for i, config in enumerate(search_spaces):\n",
        "    model = JSC_Three_Linear_Layers()\n",
        "    config = copy.deepcopy(config)\n",
        "\n",
        "    mg = MaseGraph(model=model)\n",
        "    mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "\n",
        "    print(\"Original Graph:\")\n",
        "    for block in mg.model.seq_blocks._modules:\n",
        "      print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n",
        "\n",
        "    mg, _ = redefine_linear_transform_pass(mg, {\"config\": config})\n",
        "\n",
        "    print(\"Expanded Graph:\")\n",
        "    for block in mg.model.seq_blocks._modules:\n",
        "      print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n",
        "\n",
        "    model = mg.model\n",
        "\n",
        "    train(model, model_info, data_module, dataset_info, task,\n",
        "          optimizer=\"adam\", learning_rate=1e-5, weight_decay=0,\n",
        "          plt_trainer_args=plt_trainer_args, auto_requeue=False,\n",
        "          save_path=None, visualizer=None, load_name=None, load_type=None)\n",
        "\n",
        "    test_results = test(model, model_info, data_module, dataset_info, task,\n",
        "                        optimizer=\"adam\", learning_rate=1e-5, weight_decay=0,\n",
        "                        plt_trainer_args=plt_trainer_args, auto_requeue=False,\n",
        "                        save_path=None, visualizer=None, load_name=None, load_type=None,\n",
        "                      return_test_results=True)\n",
        "\n",
        "    acc_avg = test_results[0]['test_acc_epoch']\n",
        "    loss_avg = test_results[0]['test_loss_epoch']\n",
        "    recorded_accs.append(acc_avg)\n",
        "\n",
        "    if acc_avg > best_acc:\n",
        "      best_acc = acc_avg\n",
        "      best_multiplier = config['seq_blocks_2']['config']['channel_multiplier']\n",
        "\n",
        "  print(f\"Best Accuracy: {best_acc}\\nBest Channel Multiplier: {best_multiplier}\")\n",
        "\n",
        "  return best_acc, best_multiplier, recorded_accs\n",
        "\n",
        "\n",
        "best_acc, best_multiplier, recorded_accs = brute_force(search_spaces)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n1aVw5qVAHFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4 Question 3\n",
        "\n",
        "import torch\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "from chop.actions.train import train\n",
        "from chop.actions.test import test\n",
        "\n",
        "### Define Search Space\n",
        "\n",
        "pass_config = {\n",
        "\"by\": \"name\",\n",
        "\"default\": {\"config\": {\"name\": None}},\n",
        "\"seq_blocks_2\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"output_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_4\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"both\",\n",
        "        \"channel_multiplier_in\": 2,\n",
        "        \"channel_multiplier_out\": 2,\n",
        "        }\n",
        "    },\n",
        "\"seq_blocks_6\": {\n",
        "    \"config\": {\n",
        "        \"name\": \"input_only\",\n",
        "        \"channel_multiplier\": 2,\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "channel_multipliers = [1, 2, 3, 4]\n",
        "\n",
        "search_spaces = []\n",
        "for channel_multiplier_1 in channel_multipliers:\n",
        "  for channel_multiplier_2 in channel_multipliers:\n",
        "    pass_config['seq_blocks_2']['config']['channel_multiplier'] = channel_multiplier_1\n",
        "    pass_config['seq_blocks_4']['config']['channel_multiplier_in'] = channel_multiplier_1\n",
        "    pass_config['seq_blocks_4']['config']['channel_multiplier_out'] = channel_multiplier_2\n",
        "    pass_config['seq_blocks_6']['config']['channel_multiplier'] = channel_multiplier_2\n",
        "    search_spaces.append(copy.deepcopy(pass_config))\n",
        "\n",
        "def redefine_linear_transform_pass(graph, pass_args=None):\n",
        "    main_config = pass_args.pop('config')\n",
        "    default = main_config.pop('default', None)\n",
        "    if default is None:\n",
        "        raise ValueError(f\"default value must be provided.\")\n",
        "    i = 0\n",
        "    for node in graph.fx_graph.nodes:\n",
        "        i += 1\n",
        "        # if node name is not matched, it won't be tracked\n",
        "        config = main_config.get(node.name, default)['config']\n",
        "        name = config.get(\"name\", None)\n",
        "        if name is not None:\n",
        "            ori_module = graph.modules[node.target]\n",
        "            in_features = ori_module.in_features\n",
        "            out_features = ori_module.out_features\n",
        "            bias = ori_module.bias\n",
        "            if name == \"output_only\":\n",
        "                out_features = out_features * config[\"channel_multiplier\"]\n",
        "            elif name == \"both\":\n",
        "                in_features = in_features * config[\"channel_multiplier_in\"]\n",
        "                out_features = out_features * config[\"channel_multiplier_out\"]\n",
        "            elif name == \"input_only\":\n",
        "                in_features = in_features * config[\"channel_multiplier\"]\n",
        "            new_module = instantiate_linear(in_features, out_features, bias)\n",
        "            parent_name, name = get_parent_name(node.target)\n",
        "            setattr(graph.modules[parent_name], name, new_module)\n",
        "    return graph, {}\n",
        "\n",
        "def brute_force(search_spaces):\n",
        "\n",
        "  best_acc = 0\n",
        "\n",
        "  recorded_accs = []\n",
        "\n",
        "  study = {}\n",
        "\n",
        "  for i, config in enumerate(search_spaces):\n",
        "    model = JSC_Three_Linear_Layers()\n",
        "    config = copy.deepcopy(config)\n",
        "\n",
        "    mg = MaseGraph(model=model)\n",
        "    mg, _ = init_metadata_analysis_pass(mg, None)\n",
        "\n",
        "    print(\"Original Graph:\")\n",
        "    for block in mg.model.seq_blocks._modules:\n",
        "      print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n",
        "\n",
        "    mg, _ = redefine_linear_transform_pass(mg, {\"config\": config})\n",
        "\n",
        "    print(\"Expanded Graph:\")\n",
        "    for block in mg.model.seq_blocks._modules:\n",
        "      print(f\"Block number {block}: {mg.model.seq_blocks._modules[block]}\")\n",
        "\n",
        "    model = mg.model\n",
        "\n",
        "    train(model, model_info, data_module, dataset_info, task,\n",
        "          optimizer=\"adam\", learning_rate=1e-5, weight_decay=0,\n",
        "          plt_trainer_args=plt_trainer_args, auto_requeue=False,\n",
        "          save_path=None, visualizer=None, load_name=None, load_type=None)\n",
        "\n",
        "    test_results = test(model, model_info, data_module, dataset_info, task,\n",
        "                        optimizer=\"adam\", learning_rate=1e-5, weight_decay=0,\n",
        "                        plt_trainer_args=plt_trainer_args, auto_requeue=False,\n",
        "                        save_path=None, visualizer=None, load_name=None, load_type=None,\n",
        "                      return_test_results=True)\n",
        "\n",
        "    acc_avg = test_results[0]['test_acc_epoch']\n",
        "    loss_avg = test_results[0]['test_loss_epoch']\n",
        "    recorded_accs.append(acc_avg)\n",
        "\n",
        "    if acc_avg > best_acc:\n",
        "      best_acc = acc_avg\n",
        "      best_multiplier_1 = config['seq_blocks_2']['config']['channel_multiplier']\n",
        "      best_multiplier_2 = config['seq_blocks_6']['config']['channel_multiplier']\n",
        "\n",
        "  print(f\"Best Accuracy: {best_acc}\\nBest Channel Multiplier 1: {best_multiplier_1}\\nBest Channel Multiplier 2: {best_multiplier_2}\")\n",
        "\n",
        "  return best_acc, best_multiplier_1, best_multiplier_2, recorded_accs\n",
        "\n",
        "\n",
        "best_acc, best_multiplier_1, best_multiplier_2, recorded_accs = brute_force(search_spaces)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-unheLoTKlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc_matrix = np.array(recorded_accs).reshape(4, 4)\n",
        "\n",
        "channel_multiplier_1 = ['1', '2', '3', '4']\n",
        "channel_multiplier_2 = ['1', '2', '3', '4']\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(acc_matrix, annot=True, fmt=\".2f\", cmap='Blues',\n",
        "            xticklabels=channel_multiplier_1, yticklabels=channel_multiplier_2)\n",
        "\n",
        "plt.xlabel('Channel Multiplier 1')\n",
        "plt.ylabel('Channel Multiplier 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T6hF8cxuD_UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4 Question 4\n",
        "\n",
        "!./ch search --load-type \"pl\" --config \"configs/examples/search_linear_channel_multiplier.toml\" --project-dir \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/searches_output/L4Q4\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ukbVhquf4UpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4 - Optional Question\n",
        "\n",
        "!./ch search --load-type \"pl\" --config \"configs/examples/search_convolutional_filters_multiplier.toml\" --project-dir \"/content/drive/MyDrive/AppliedMachineLearning/AdvancedDeepLearningSystems/MASErepo2/mase2/mase_output/searches_output/L4Q5\"\n",
        "\n"
      ],
      "metadata": {
        "id": "p-TK1uDgzCIR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}